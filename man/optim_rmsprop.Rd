% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optim_rmsprop.R
\name{optim_rsmprop}
\alias{optim_rsmprop}
\title{RMSprop optimizer}
\usage{
optim_rsmprop(
  params,
  lr = 0.01,
  alpha = 0.99,
  eps = 1e-08,
  weight_decay = 0,
  momentum = 0,
  centered = FALSE
)
}
\arguments{
\item{params}{(iterable): iterable of parameters to optimize or list defining parameter groups}

\item{lr}{(float, optional): learning rate (default: 1e-2)}

\item{alpha}{(float, optional): smoothing constant (default: 0.99)}

\item{eps}{(float, optional): term added to the denominator to improve
numerical stability (default: 1e-8)}

\item{momentum}{(float, optional): momentum factor (default: 0)}

\item{centered}{(bool, optional) : if \code{TRUE}, compute the centered RMSProp,
the gradient is normalized by an estimation of its variance
weight_decay (float, optional): weight decay (L2 penalty) (default: 0)}
}
\description{
Proposed by G. Hinton in his
\link[=**course**]{\strong{course}} (https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)
}
\note{
The centered version first appears in \verb{Generating Sequences With Recurrent Neural Networks <https://arxiv.org/pdf/1308.0850v5.pdf>}_.
The implementation here takes the square root of the gradient average before
adding epsilon (note that TensorFlow interchanges these two operations). The effective
learning rate is thus :math:\verb{\\alpha/(\\sqrt\{v\} + \\epsilon)} where :math:\verb{\\alpha}
is the scheduled learning rate and :math:\code{v} is the weighted moving average
of the squared gradient.

Update rule:

deqn{
\theta_{t+1} = \theta_{t} - \frac{\eta }{\sqrt{{E\link{g^2}}\emph{{t} + \epsilon}} * g}{t}
}
}
